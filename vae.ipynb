{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"T:\\Program Files\\JetBrains\\PyCharm 2021.3.2\\plugins\\python\\helpers\\pydev\\_pydevd_bundle\\pydevd_comm.py\", line 459, in start_client\n",
      "    s.connect((host, port))\n",
      "ConnectionRefusedError: [WinError 10061] Nie można nawiązać połączenia, ponieważ komputer docelowy aktywnie go odmawia\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"T:\\Program Files\\JetBrains\\PyCharm 2021.3.2\\plugins\\python\\helpers-pro\\jupyter_debug\\pydev_jupyter_utils.py\", line 81, in attach_to_debugger\n",
      "    debugger.connect(pydev_localhost.get_localhost(), debugger_port)\n",
      "  File \"T:\\Program Files\\JetBrains\\PyCharm 2021.3.2\\plugins\\python\\helpers\\pydev\\pydevd.py\", line 657, in connect\n",
      "    s = start_client(host, port)\n",
      "  File \"T:\\Program Files\\JetBrains\\PyCharm 2021.3.2\\plugins\\python\\helpers\\pydev\\_pydevd_bundle\\pydevd_comm.py\", line 459, in start_client\n",
      "    s.connect((host, port))\n",
      "KeyboardInterrupt\n",
      "Failed to connect to target debugger.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import numpy\n",
    "import matplotlib.pyplot\n",
    "\n",
    "img_size = 28\n",
    "num_channels = 1\n",
    "latent_space_dim = 16\n",
    "\n",
    "# Encoder\n",
    "x = tensorflow.keras.layers.Input(shape=(img_size, img_size, num_channels), name=\"encoder_input\")\n",
    "\n",
    "encoder_conv_layer1 = tensorflow.keras.layers.Conv2D(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1, name=\"encoder_conv_1\")(x)\n",
    "encoder_norm_layer1 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_1\")(encoder_conv_layer1)\n",
    "encoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_leakyrelu_1\")(encoder_norm_layer1)\n",
    "\n",
    "encoder_conv_layer2 = tensorflow.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding=\"same\", strides=1, name=\"encoder_conv_2\")(encoder_activ_layer1)\n",
    "encoder_norm_layer2 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_2\")(encoder_conv_layer2)\n",
    "encoder_activ_layer2 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_activ_layer_2\")(encoder_norm_layer2)\n",
    "\n",
    "encoder_conv_layer3 = tensorflow.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=2, name=\"encoder_conv_3\")(encoder_activ_layer2)\n",
    "encoder_norm_layer3 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_3\")(encoder_conv_layer3)\n",
    "encoder_activ_layer3 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_activ_layer_3\")(encoder_norm_layer3)\n",
    "\n",
    "encoder_conv_layer4 = tensorflow.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=2, name=\"encoder_conv_4\")(encoder_activ_layer3)\n",
    "encoder_norm_layer4 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_4\")(encoder_conv_layer4)\n",
    "encoder_activ_layer4 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_activ_layer_4\")(encoder_norm_layer4)\n",
    "\n",
    "encoder_conv_layer5 = tensorflow.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", strides=1, name=\"encoder_conv_5\")(encoder_activ_layer4)\n",
    "encoder_norm_layer5 = tensorflow.keras.layers.BatchNormalization(name=\"encoder_norm_5\")(encoder_conv_layer5)\n",
    "encoder_activ_layer5 = tensorflow.keras.layers.LeakyReLU(name=\"encoder_activ_layer_5\")(encoder_norm_layer5)\n",
    "\n",
    "shape_before_flatten = tensorflow.keras.backend.int_shape(encoder_activ_layer5)[1:]\n",
    "encoder_flatten = tensorflow.keras.layers.Flatten()(encoder_activ_layer5)\n",
    "\n",
    "encoder_mu = tensorflow.keras.layers.Dense(units=latent_space_dim, name=\"encoder_mu\")(encoder_flatten)\n",
    "encoder_log_variance = tensorflow.keras.layers.Dense(units=latent_space_dim, name=\"encoder_log_variance\")(encoder_flatten)\n",
    "\n",
    "encoder_mu_log_variance_model = tensorflow.keras.models.Model(x, (encoder_mu, encoder_log_variance), name=\"encoder_mu_log_variance_model\")\n",
    "\n",
    "def sampling(mu_log_variance):\n",
    "    mu, log_variance = mu_log_variance\n",
    "    epsilon = tensorflow.keras.backend.random_normal(shape=tensorflow.keras.backend.shape(mu), mean=0.0, stddev=1.0)\n",
    "    random_sample = mu + tensorflow.keras.backend.exp(log_variance/2) * epsilon\n",
    "    return random_sample\n",
    "\n",
    "encoder_output = tensorflow.keras.layers.Lambda(sampling, name=\"encoder_output\")([encoder_mu, encoder_log_variance])\n",
    "\n",
    "encoder = tensorflow.keras.models.Model(x, encoder_output, name=\"encoder_model\")\n",
    "encoder.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " decoder_input (InputLayer)  [(None, 16)]              0         \n",
      "                                                                 \n",
      " decoder_dense_1 (Dense)     (None, 3136)              53312     \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " decoder_conv_tran_1 (Conv2D  (None, 7, 7, 64)         36928     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " decoder_norm_1 (BatchNormal  (None, 7, 7, 64)         256       \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " decoder_leakyrelu_1 (LeakyR  (None, 7, 7, 64)         0         \n",
      " eLU)                                                            \n",
      "                                                                 \n",
      " decoder_conv_tran_2 (Conv2D  (None, 14, 14, 64)       36928     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " decoder_norm_2 (BatchNormal  (None, 14, 14, 64)       256       \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " decoder_leakyrelu_2 (LeakyR  (None, 14, 14, 64)       0         \n",
      " eLU)                                                            \n",
      "                                                                 \n",
      " decoder_conv_tran_3 (Conv2D  (None, 28, 28, 64)       36928     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " decoder_norm_3 (BatchNormal  (None, 28, 28, 64)       256       \n",
      " ization)                                                        \n",
      "                                                                 \n",
      " decoder_leakyrelu_3 (LeakyR  (None, 28, 28, 64)       0         \n",
      " eLU)                                                            \n",
      "                                                                 \n",
      " decoder_conv_tran_4 (Conv2D  (None, 28, 28, 1)        577       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " decoder_output (LeakyReLU)  (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165,441\n",
      "Trainable params: 165,057\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder_input = tensorflow.keras.layers.Input(shape=(latent_space_dim), name=\"decoder_input\")\n",
    "decoder_dense_layer1 = tensorflow.keras.layers.Dense(units=numpy.prod(shape_before_flatten), name=\"decoder_dense_1\")(decoder_input)\n",
    "decoder_reshape = tensorflow.keras.layers.Reshape(target_shape=shape_before_flatten)(decoder_dense_layer1)\n",
    "\n",
    "decoder_conv_tran_layer1 = tensorflow.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=1, name=\"decoder_conv_tran_1\")(decoder_reshape)\n",
    "decoder_norm_layer1 = tensorflow.keras.layers.BatchNormalization(name=\"decoder_norm_1\")(decoder_conv_tran_layer1)\n",
    "decoder_activ_layer1 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_1\")(decoder_norm_layer1)\n",
    "\n",
    "decoder_conv_tran_layer2 = tensorflow.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=2, name=\"decoder_conv_tran_2\")(decoder_activ_layer1)\n",
    "decoder_norm_layer2 = tensorflow.keras.layers.BatchNormalization(name=\"decoder_norm_2\")(decoder_conv_tran_layer2)\n",
    "decoder_activ_layer2 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_2\")(decoder_norm_layer2)\n",
    "\n",
    "decoder_conv_tran_layer3 = tensorflow.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), padding=\"same\", strides=2, name=\"decoder_conv_tran_3\")(decoder_activ_layer2)\n",
    "decoder_norm_layer3 = tensorflow.keras.layers.BatchNormalization(name=\"decoder_norm_3\")(decoder_conv_tran_layer3)\n",
    "decoder_activ_layer3 = tensorflow.keras.layers.LeakyReLU(name=\"decoder_leakyrelu_3\")(decoder_norm_layer3)\n",
    "\n",
    "decoder_conv_tran_layer4 = tensorflow.keras.layers.Conv2DTranspose(filters=1, kernel_size=(3, 3), padding=\"same\", strides=1, name=\"decoder_conv_tran_4\")(decoder_activ_layer3)\n",
    "decoder_output = tensorflow.keras.layers.LeakyReLU(name=\"decoder_output\")(decoder_conv_tran_layer4 )\n",
    "\n",
    "decoder = tensorflow.keras.models.Model(decoder_input, decoder_output, name=\"decoder_model\")\n",
    "decoder.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"VAE\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " VAE_input (InputLayer)      [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " encoder_model (Functional)  (None, 16)                193966    \n",
      "                                                                 \n",
      " decoder_model (Functional)  (None, 28, 28, 1)         165441    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 359,407\n",
      "Trainable params: 358,573\n",
      "Non-trainable params: 834\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vae_input = tensorflow.keras.layers.Input(shape=(img_size, img_size, num_channels), name=\"VAE_input\")\n",
    "vae_encoder_output = encoder(vae_input)\n",
    "vae_decoder_output = decoder(vae_encoder_output)\n",
    "vae = tensorflow.keras.models.Model(vae_input, vae_decoder_output, name=\"VAE\")\n",
    "vae.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "def loss_func(encoder_mu, encoder_log_variance):\n",
    "    def vae_reconstruction_loss(y_true, y_predict):\n",
    "        reconstruction_loss_factor = 1000\n",
    "        reconstruction_loss = tensorflow.keras.backend.mean(tensorflow.keras.backend.square(y_true-y_predict), axis=[1, 2, 3])\n",
    "        return reconstruction_loss_factor * reconstruction_loss\n",
    "\n",
    "    def vae_kl_loss(encoder_mu, encoder_log_variance):\n",
    "        kl_loss = -0.5 * tensorflow.keras.backend.sum(1.0 + encoder_log_variance - tensorflow.keras.backend.square(encoder_mu) - tensorflow.keras.backend.exp(encoder_log_variance), axis=1)\n",
    "        return kl_loss\n",
    "\n",
    "    def vae_kl_loss_metric(y_true, y_predict):\n",
    "        kl_loss = -0.5 * tensorflow.keras.backend.sum(1.0 + encoder_log_variance - tensorflow.keras.backend.square(encoder_mu) - tensorflow.keras.backend.exp(encoder_log_variance), axis=1)\n",
    "        return kl_loss\n",
    "\n",
    "    def vae_loss(y_true, y_predict):\n",
    "        reconstruction_loss = vae_reconstruction_loss(y_true, y_predict)\n",
    "        kl_loss = vae_kl_loss(y_true, y_predict)\n",
    "\n",
    "        loss = reconstruction_loss + kl_loss\n",
    "        return loss\n",
    "\n",
    "    return vae_loss\n",
    "\n",
    "vae.compile(optimizer=tensorflow.keras.optimizers.Adam(learning_rate=0.0005), loss=loss_func(encoder_mu, encoder_log_variance))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 25s 12ms/step - loss: 25.9501 - val_loss: 19.3762\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 15.8255 - val_loss: 14.0659\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 13.7812 - val_loss: 13.1052\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 12.6251 - val_loss: 11.9795\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 11.8672 - val_loss: 11.2451\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 11.2989 - val_loss: 12.1690\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 10.8655 - val_loss: 10.6809\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 10.5445 - val_loss: 10.3710\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 22s 12ms/step - loss: 10.2454 - val_loss: 10.2297\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 10.0598 - val_loss: 9.9089\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 9.8497 - val_loss: 9.8471\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 9.7156 - val_loss: 9.7662\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 25s 13ms/step - loss: 9.5522 - val_loss: 9.5126\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 9.4555 - val_loss: 9.4374\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 9.3550 - val_loss: 9.3814\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 9.2519 - val_loss: 9.5901\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 9.1660 - val_loss: 9.3519\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 21s 11ms/step - loss: 9.0843 - val_loss: 9.6282\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 24s 13ms/step - loss: 9.0066 - val_loss: 9.1828\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 23s 12ms/step - loss: 8.9681 - val_loss: 9.5289\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x159023fdbb0>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.mnist.load_data()\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "x_train = numpy.reshape(x_train, newshape=(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
    "x_test = numpy.reshape(x_test, newshape=(x_test.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
    "\n",
    "vae.fit(x_train, x_train, epochs=20, batch_size=32, shuffle=True, validation_data=(x_test, x_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "encoder.save_weights(\"VAE_encoder.h5\")\n",
    "decoder.save_weights(\"VAE_decoder.h5\")\n",
    "vae.save(\"VAE.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df\n"
     ]
    }
   ],
   "source": [
    "#encoder = tensorflow.keras.models.load_model(\"VAE_encoder.h5\", compile=False)\n",
    "#decoder = tensorflow.keras.models.load_model(\"VAE_decoder.h5\", compile=False)\n",
    "encoder.load_weights(\"VAE_encoder.h5\")\n",
    "decoder.load_weights(\"VAE_decoder.h5\")\n",
    "\n",
    "# Preparing MNIST Dataset\n",
    "(x_train, y_train), (x_test, y_test) = tensorflow.keras.datasets.mnist.load_data()\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "inp = x_test\n",
    "x_test = numpy.reshape(x_test, newshape=(x_test.shape[0], x_train.shape[1], x_train.shape[2], 1))\n",
    "\n",
    "encoded_data = encoder.predict(x_test)\n",
    "decoded_data = decoder.predict(encoded_data)\n",
    "\n",
    "decoded_data2 = numpy.reshape(decoded_data, newshape=(decoded_data.shape[0], decoded_data.shape[1], decoded_data.shape[2]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}